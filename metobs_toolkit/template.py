#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Tue Apr 30 09:48:24 2024

@author: thoverga
"""

import os
import sys
import logging
import json


import pandas as pd
from pytz import all_timezones

# from metobs_toolkit.data_import import _read_csv_to_df

logger = logging.getLogger(__name__)


# blacklists are created for column names, which are also used as a specific
# column that is often generated by the toolkit.

column_data_blacklist = (
    []
)  # When this column is found, a 'underscar' is added to the name,
column_meta_blacklist = [
    "geometry",
    "assumed_import_frequency",
    "dataset_resolution",
    "lcz",
    "altitude",
]


def _get_empty_templ_dict():
    templ_dict = {
        # data file
        "data_related": {
            "structure": None,  # long, wide or singl-station
            "timestamp": {
                "datetime_column": None,
                "datetime_fmt": None,
                "date_column": None,
                "date_fmt": None,
                "time_column": None,
                "time_fmt": None,
                "timezone": None,
            },
            "name_column": None,
            "obstype_mapping": [
                {
                    "tlk_obstype": None,
                    "columnname": None,
                    "unit": None,
                    "description": None,
                },
            ],
        },
        # Meta data file
        "metadata_related": {
            "name_column": None,
            "lat_column": None,
            "lon_column": None,
            "columns_to_include": [],
        },
        # extra settings
        "single_station_name": "dummy_station_name",
    }
    return templ_dict


def _pwrite_templdict_to_json(templdict, trgfile):
    j = json.dumps(templdict, indent=4)
    with open(trgfile, "w") as f:
        print(j, file=f)
    return


class Template:
    """Contains all info and methods to work with a template."""

    def __init__(self):
        # to renmae the columns

        self.data_namemap = {"name": None}  # name --> name column in data
        self.metadata_namemap = {"name": None}  # name --> name column in metadata

        # obstypes details
        self.obscolumnmap = {}  # toolkitname --> datacolumnname
        self.obsdetails = {}  # obsname(tlk) --> {unit: , description: ..}

        self.metacolmapname = {}  # toolkitname --> metadatacolumnname

        # Special always required
        self.dataformat = (
            "long"  # long or wide (single station is converted to long on import)
        )

        # For single stations data
        self.data_is_single_station = False  # datafmt is assumed to be long, but name column is not required in the data
        self.single_station_name = None

        self.timestampinfo = {
            "datetimecolumn": None,
            "time_column": None,
            "date_column": None,
            "fmt": None,
        }

        # Extra options (not required)
        self.tz = None

        # Not activaly used attributes
        self.filepath = None

    def get_info(self):
        key_len = 15
        print("------ Data obstypes map ---------")
        for key, val in self.obscolumnmap.items():
            print(f" * {key.ljust(key_len)} <---> {str(val).ljust(key_len)}")

        print("\n------ Data extra mapping info ---------")

        print(
            f" * {'name column (data)'.ljust(key_len)} <---> {str(self.data_namemap['name'])}"
        )
        if self.data_is_single_station:
            print(
                f" * {'single station name'.ljust(key_len)} <---> {self.single_station_name}"
            )

        print("\n------ Data timestamp map ---------")
        for key, val in self.timestampinfo.items():
            print(f" * {key.ljust(key_len)} <---> {str(val).ljust(key_len)}")
        print(f" * {'Timezone'.ljust(key_len)} <---> {self.tz}")

        print("\n------ Metadata map ---------")
        for key, val in self.metacolmapname.items():
            print(f" * {key.ljust(key_len)} <---> {str(val).ljust(key_len)}")

    # =============================================================================
    # Setters
    # =============================================================================
    def _set_dataname(self, datanamecolumn):
        """Overwrite the data name column"""
        self.data_namemap["name"] = str(datanamecolumn)

    def _set_dataformat(self, datafmt):
        """Overwrite the dataformat"""
        if str(datafmt) == "long":
            self.dataformat = "long"
        elif str(datafmt) == "wide":
            self.dataformat = "wide"
        elif str(datafmt) == "single_station":
            # Data format is long, but indicate that data represents a single station
            self.dataformat = "long"
            self.data_is_single_station = True

        else:
            sys.exit(f"{datafmt} is not a known dataformat.")

    # def _set_wide_obstype(self, obstypename, obstype_unit, obstype_descr):
    #     if obstypename is not None:
    #         self.obsdetails[str(obstypename)] = {
    #             "unit": str(obstype_unit),
    #             "description": str(obstype_descr),
    #         }

    # def _set_filepath(self, filepath):
    #     self.filepath = str(filepath)

    # def _set_dataformat(self, datafmt):
    #     if str(datafmt).lower() == "long":
    #         self.dataformat = "long"
    #         return
    #     if str(datafmt).lower() == "wide":
    #         self.dataformat = "wide"
    #         return
    #     if str(datafmt).lower() == "single_station":
    #         # A single station format is in principle a long format,
    #         #without a name column.
    #         self.dataformat = "long"
    #         return
    #     sys.exit(
    #         f"The data format specified in the template ({datafmt}) is neither long, wide or single_station"
    #     )

    # def _set_obs_info(self, obstempldf):
    #     for _idx, row in obstempldf.iterrows():
    #         self.obscolumnmap[str(row["varname"])] = str(row["template column name"])

    #         self.obsdetails[str(row["varname"])] = {
    #             "unit": str(row["units"]),
    #             "description": str(row["description"]),
    #         }

    # def _set_name(self, namecolumn):
    #     self.namemap["name"] = str(namecolumn)

    # def _set_tz(self, tzstring):
    #     if str(tzstring) in all_timezones:
    #         self.tz = str(tzstring)
    #         return
    #     sys.exit(
    #         f"{tzstring} is not a valid timezone string. See pytz.all_timezones for all valid timezone strings."
    #     )

    # def _set_timestampinfo(self, templdf):

    #     if "datetime" in templdf["varname"].values:
    #         # get columnname of the timestamps
    #         self.timestampinfo["datetimecolumn"] = str(
    #             templdf.loc[
    #                 templdf["varname"] == "datetime", "template column name"
    #             ].squeeze()
    #         )
    #         # get the datetime format
    #         self.timestampinfo["fmt"] = str(
    #             templdf.loc[templdf["varname"] == "datetime", "format"].squeeze()
    #         )
    #         return
    #     if "_date" in templdf["varname"].values:
    #         if "_time" in templdf["varname"].values:
    #             # get columnname of the timestamps
    #             self.timestampinfo["date_column"] = str(
    #                 templdf.loc[
    #                     templdf["varname"] == "_date", "template column name"
    #                 ].squeeze()
    #             )
    #             self.timestampinfo["time_column"] = str(
    #                 templdf.loc[
    #                     templdf["varname"] == "_time", "template column name"
    #                 ].squeeze()
    #             )

    #             # get the datetime format
    #             date_fmt = str(
    #                 templdf.loc[templdf["varname"] == "_date", "format"].squeeze()
    #             )
    #             time_fmt = str(
    #                 templdf.loc[templdf["varname"] == "_time", "format"].squeeze()
    #             )
    #             self.timestampinfo["fmt"] = (
    #                 f"{date_fmt} {time_fmt}"  # concat with space inbetween
    #             )
    #             return
    #         else:
    #             sys.exit(
    #                 "No time column is mapped by the template (_date is mapped, but not _time)."
    #             )

    #     else:
    #         sys.exit(
    #             "No datetime columns are mapped by the template. Neither datetime or a _date and _time combination is found."
    #         )

    # =============================================================================
    # OVerwriters (from method args)
    # =============================================================================
    # def _overwrite_data_format(self, long_fmt):
    #     """
    #     Arguments passed to Dataset.read_from_file() overwrite those from
    #     the templatefile.
    #     """

    #     if long_fmt is None:
    #         # keep format from template
    #         return
    #     else:
    #         assert long_fmt in ["long", "wide"], f'{long_fmt} is not "long" or "wide".'
    #         self.dataformat = str(long_fmt)
    #     return

    # =============================================================================
    # Getters (used by other classes to extract specific data from a template)
    # =============================================================================
    def _is_data_long(self):
        return self.dataformat == "long"

    def _is_data_single_station(self):
        return self.data_is_single_station

    def _get_wide_obstype(self):
        """Get the name of the wide obstype, in tlk space"""
        return list(self.obsdetails.keys())[0]

    def _get_tz(self):
        """Get the timezone string"""
        return self.tz

    def _get_data_name_map(self):
        """Get the name-map for the data file"""
        return {self.data_namemap["name"]: "name"}

    def _get_metadata_name_map(self):
        """Get the name-map for the metadata file"""
        return {self.metadata_namemap["name"]: "name"}

    def _get_metadata_column_map(self):
        """Get the mapper for all metadata columns (name, lat, lon included)"""
        return {val: key for key, val in self.metacolmapname.items()}

    def _get_obs_column_map(self):
        """Get mapper for al the observations columns of the data (for long format)"""
        # Check if datetime mapping is valid
        self._check_if_datetime_is_mapped()
        columnmmap = {}
        if self.dataformat == "long":

            # add all obstype columns
            for key, val in self.obscolumnmap.items():
                columnmmap[val] = key
        else:
            pass  # no mapping done on wide
        return columnmmap

    def _get_all_mapped_data_cols_in_tlk_space(self):
        # all mapped columns are: name, datetime and all mapped obstypes
        mapped_cols = ["name", "datetime"]
        if self.dataformat == "long":
            mapped_cols.extend(list(self.obscolumnmap.keys()))
        else:
            # wide only represents one obstype
            mapped_cols.append(list(self.obsdetails.keys())[0])
        return mapped_cols

    def _get_original_obstype_columnname(self, obstypename):
        return str(self.obscolumnmap[obstypename])

    def _get_input_unit_of_tlk_obstype(self, obstypename):
        return str(self.obsdetails[obstypename]["unit"])

    def _get_description_of_tlk_obstype(self, obstypename):
        return str(self.obsdetails[obstypename]["description"])

    # =============================================================================
    # Validity checkers
    # =============================================================================
    def _check_if_datetime_is_mapped(self):
        ts_info = self.timestampinfo
        # situation 1:  datetime column is present
        if ts_info["datetimecolumn"] is not None:
            assert (
                ts_info["fmt"] is not None
            ), f"Datetimes are assumed to be present in ONE column, but no datetime format is specified."
            if ts_info["time_column"] is not None:
                self.timestampinfo["time_column"] = None
                logger.warning(
                    f"The mapping of the time column ({ts_info['time_column']}) is ignored because of the presence of a datetime column."
                )
            if ts_info["date_column"] is not None:
                self.timestampinfo["date_column"] = None
                logger.warning(
                    f"The mapping of the date column ({ts_info['date_column']}) is ignored because of the presence of a datetime column."
                )
            return

        # Situation 2: a seperate date and time columns is present.
        if (ts_info["time_column"] is not None) & (ts_info["date_column"] is not None):
            assert (
                ts_info["fmt"] is not None
            ), f"Datetimes are assumed to be present as a date and time column, but no formats are specified."
            return
        sys.exit(
            "The timestamps are not correctly mapped (either by using a datetime column, or by a time and date column)"
        )

    def _data_template_compatibility_test(self, datacolumns):
        """Check the compatibility of the template and the columns of the data"""

        # check datetime
        self._check_if_datetime_is_mapped()
        if self.timestampinfo["datetimecolumn"] is not None:
            if not (self.timestampinfo["datetimecolumn"] in datacolumns):
                raise MetobsTemplateError(
                    f'The column {self.timestampinfo["datetimecolumn"]} is incorrectly mapped in the template as the "datetime" column. The template is therefore not valid with the data.'
                )

        if self.timestampinfo["time_column"] is not None:
            if not (self.timestampinfo["time_column"] in datacolumns):
                raise MetobsTemplateError(
                    f'The column {self.timestampinfo["time_column"]} is incorrectly mapped in the template as the "_time" column. The template is therefore not valid with the data.'
                )

        if self.timestampinfo["date_column"] is not None:
            if not (self.timestampinfo["date_column"] in datacolumns):
                raise MetobsTemplateError(
                    f'The column {self.timestampinfo["date_column"]} is incorrectly mapped in the template as the "_date" column. The template is therefore not valid with the data.'
                )

        if self._is_data_long():
            # check name column
            if not self._is_data_single_station():
                if not (self.data_namemap["name"] in datacolumns):
                    raise MetobsTemplateError(
                        f'The column {self.data_namemap["name"]} is not (or incorrectly) mapped in the template as the "name" column. The template is therefore not valid with the data.'
                    )

            # check of templates has obstypes not present in the data
            for mapped_obscol in self.obscolumnmap.values():
                if mapped_obscol not in datacolumns:
                    msg = f"{mapped_obscol} is a mapped observation, present in the template but not found in the data! This obstype will be ignored."
                    logger.warning(msg)

            # check if data has obstypes not present in the template
            for data_col in datacolumns:
                if data_col in [
                    self.data_namemap["name"],
                    self.timestampinfo["datetimecolumn"],
                    self.timestampinfo["time_column"],
                    self.timestampinfo["date_column"],
                ]:
                    continue

                if data_col not in self.obscolumnmap.values():
                    msg = f"{data_col} is present in the datafile, but not found in the template! This column will be ignored."
                    logger.warning(msg)

        else:
            # wide tests"
            # all columns are assumed to be station names
            pass

    def _metadata_template_compatibility_test(self, metadatacolumns):
        """Check the compatibility of the template and the columns of the metadata"""

        # check name column (must be present if multiple station are in the data)
        if not self._is_data_single_station():
            if not (self.metadata_namemap["name"] in metadatacolumns):
                raise MetobsTemplateError(
                    f'The column {self.metadata_namemap["name"]} is not (or incorrectly) mapped in the template as the "name" column. The template is therefore not valid with the metadata.'
                )

        # check if templates contains mapped columns not present in the metadata
        for mapped_col in self.metacolmapname.values():
            if mapped_col not in metadatacolumns:
                msg = f"{mapped_col} is a mapped metadata column, present in the template but not found in the metadata! This column will be ignored."
                logger.warning(msg)

        # check if metadata has columns which are not mapped by the template
        unmapped = (
            set(metadatacolumns) - set(self.metacolmapname.values()) - set(["name"])
        )
        if not bool(unmapped):
            msg = f"The following columns are found in the metadata, but not in the template and are therefore ignored: \n{list(unmapped)}"
            logger.warning(msg)

    def _apply_blacklist(self, columns, on_data):
        """Create a mapper for columns in the data or metadata file, which have
        a specific meaning by the toolkit and are thus present in the blacklists.

        If a column, is found in the blacklist, but will also be mapped, than it
        it will not be included in the mapper.

        The mapper adds a "_original" postifix to the columnnames.
        """

        if on_data:
            blacklist = column_data_blacklist
        else:
            blacklist = column_meta_blacklist

        to_rename = [col for col in columns if col in column_data_blacklist]

        if on_data:
            # if the columns is mapped by the template, remove it from the to_rename
            mapped_set = set(
                [
                    self.data_namemap["name"],  # name col
                    self.timestampinfo["datetimecolumn"],
                    self.timestampinfo["date_column"],
                    self.timestampinfo["time_column"],
                ]
            )
            mapped_set.union(set(self._get_obs_column_map().keys()))

        else:
            # on metadata
            mapped_set = set([self.metadata_namemap["name"]])
            mapped_set.union(set(self._get_metadata_column_map().keys()))

        mapped_set = mapped_set - set([None])

        to_rename = set(to_rename) - mapped_set
        blacklist_mapper = {col: f"{col}_original" for col in to_rename}

        if not bool(blacklist_mapper):
            if on_data:
                msg = f"The following data columns are renamed because of special meaning by the toolkit: {blacklist_mapper}"
            else:
                msg = f"The following metadata columns are renamed because of special meaning by the toolkit: {blacklist_mapper}"
            logger.warning(msg)

        return blacklist_mapper

    # =============================================================================
    # Other methods
    # =============================================================================

    def read_template_from_file(self, jsonpath):

        if not str(jsonpath).endswith(".json"):
            raise MetobsTemplateError(f"{jsonpath}, is not a json file.")

        with open(jsonpath, "r") as f:
            tml_dict = json.load(f)

        # set attributes
        self.data_namemap = {"name": tml_dict["data_related"]["name_column"]}
        self.metadata_namemap = {"name": tml_dict["metadata_related"]["name_column"]}
        self._set_dataformat(tml_dict["data_related"]["structure"])
        self.single_station_name = str(tml_dict["single_station_name"])

        if tml_dict["data_related"]["timestamp"]["datetime_column"] is None:
            dt_fmt = f'{tml_dict["data_related"]["timestamp"]["date_fmt"]} {tml_dict["data_related"]["timestamp"]["time_fmt"]}'
        else:
            dt_fmt = f'{tml_dict["data_related"]["timestamp"]["datetime_fmt"]}'

        self.timestampinfo = {
            "datetimecolumn": tml_dict["data_related"]["timestamp"]["datetime_column"],
            "time_column": tml_dict["data_related"]["timestamp"]["time_column"],
            "date_column": tml_dict["data_related"]["timestamp"]["date_column"],
            "fmt": dt_fmt,
        }

        for obsdict in tml_dict["data_related"]["obstype_mapping"]:
            self.obscolumnmap[obsdict["tlk_obstype"]] = obsdict["columnname"]
            self.obsdetails[obsdict["tlk_obstype"]] = {
                "unit": obsdict["unit"],
                "description": obsdict["description"],
            }

        self.metacolmapname["name"] = tml_dict["metadata_related"]["name_column"]
        if tml_dict["metadata_related"]["lat_column"] is not None:
            self.metacolmapname["lat"] = tml_dict["metadata_related"]["lat_column"]
        if tml_dict["metadata_related"]["lon_column"] is not None:
            self.metacolmapname["lon"] = tml_dict["metadata_related"]["lon_column"]

        for extra_col in tml_dict["metadata_related"]["columns_to_include"]:
            self.metacolmapname[extra_col] = extra_col


def _create_datetime_column(df, template):
    """Use the template to construct a tz-naive "datetime" column."""

    template._check_if_datetime_is_mapped()

    if template.timestampinfo["datetimecolumn"] is not None:
        if not (template.timestampinfo["datetimecolumn"] in df.columns):
            raise MetobsTemplateError(
                f'The {template.timestampinfo["datetimecolumn"]} is not found in the columns of the data file: {df.columns}'
            )
        df = df.rename(columns={template.timestampinfo["datetimecolumn"]: "datetime"})
        df["datetime"] = pd.to_datetime(
            df["datetime"], format=template.timestampinfo["fmt"]
        )

    else:
        # by date and time column
        if not (template.timestampinfo["time_column"] in df.columns):
            raise MetobsTemplateError(
                f'The {template.timestampinfo["time_column"]} is not found in the columns of the data file: {df.columns}'
            )
        if not (template.timestampinfo["date_column"] in df.columns):
            raise MetobsTemplateError(
                f'The {template.timestampinfo["date_column"]} is not found in the columns of the data file: {df.columns}'
            )

        df = df.rename(
            columns={
                template.timestampinfo["time_column"]: "_time",
                template.timestampinfo["date_column"]: "_date",
            }
        )
        try:
            df["datetime"] = pd.to_datetime(
                df["_date"] + " " + df["_time"], format=template.timestampinfo["fmt"]
            )

        except Exception as e:
            raise MetobsTemplateError(
                "The timestamps could not be converted to datetimes, check the timestamp format(s) in your template."
            )
            # raise Exception('The timestamps could not be converted to datetimes, check the timestamp format(s) in your template. \n').with_traceback(e.__traceback__)

        df = df.drop(columns=["_date", "_time"])
    return df


# =============================================================================
# Exceptions
# =============================================================================


class MetobsTemplateError(Exception):
    """Exception raised for errors in the template."""

    pass


# def read_csv_template(file, known_obstypes, data_long_format=True):
#     """
#     Import a template from a csv file.

#     Format options will be stored in a seperate dictionary. (Because these
#     do not relate to any of the data columns.)

#     Parameters
#     ----------
#     file : str
#         Path to the csv template file.
#     known_obstypes : list
#         A list of known observation types. These consist of the default
#         obstypes and the ones added by the user.
#     data_long_format : bool, optional
#         If True, this format structure has priority over the format structure
#         in the template file. The default is True.

#     Returns
#     -------
#     template : dict
#         The template related to the data/metadata columns.
#     opt_kwargs : dict
#         Options and settings present in the template.

#     """
#     template = Template()

#     templdf = _read_csv_to_df(filepath=file, kwargsdict={})
#     # Drop emty rows
#     templdf = templdf.dropna(axis="index", how="all")

#     # Extracting general settings
#     assert (
#         "options" in templdf.columns
#     ), 'The "options" column is not present in the template.'
#     assert (
#         "options_values" in templdf.columns
#     ), 'The "options" column is not present in the template.'

#     optionsdf = templdf[["options", "options_values"]].dropna(axis="index", how="all")
#     options = dict(zip(optionsdf["options"], optionsdf["options_values"]))

#     # Updatet template attributes
#     template._set_filepath(file)

#     assert (
#         "data_structure" in options.keys()
#     ), 'the "data_structure" is a required option that must be in the "options" column of the template.'
#     template._set_dataformat(datafmt=options["data_structure"])

#     # Get timestamps info (how they are represented in the data)
#     template._set_timestampinfo(templdf=templdf)

#     if "timezone" in options:
#         template._set_tz(tzstring=options["timezone"])

#     assert (
#         "name" in templdf["varname"].values
#     ), '"name" is required in the "varname" column of the template.'
#     template._set_name(
#         namecolumn=templdf.loc[
#             templdf["varname"] == "name", "template column name"
#         ].squeeze()
#     )

#     obstempldf = templdf.loc[templdf["varname"].isin(known_obstypes)]
#     template._set_obs_info(obstempldf=obstempldf)

#     return template


# def extract_options_from_template(templ, known_obstypes):
#     """Filter out options settings from the template dataframe.

#     Parameters
#     ----------
#     templ : pandas.DataFrame()
#         Template in a dataframe structure
#     known_obstypes : list
#         A list of known observation types. These consist of the default
#         obstypes and the ones added by the user.

#     Returns
#     -------
#     new_templ : pandas.DataFrame()
#         The template dataframe with optioncolumns removed.
#     opt_kwargs : dict
#         Options and settings present in the template dataframe.

#     """
#     opt_kwargs = {}
#     if "options" in templ.columns:
#         if "options_values" in templ.columns:
#             opt = templ[["options", "options_values"]]
#             # drop nan columns
#             opt = opt[opt["options"].notna()]
#             # convert to dict
#             opt = opt.set_index("options")["options_values"].to_dict()

#             # check options if valid
#             possible_options = {
#                 "data_structure": ["long", "wide", "single_station"],
#                 "stationname": "_any_",
#                 "obstype": known_obstypes,
#                 "obstype_unit": "_any_",
#                 "obstype_description": "_any_",
#                 "timezone": all_timezones,
#             }
#             for key, val in opt.items():
#                 key, val = str(key), str(val)
#                 if key not in possible_options:
#                     sys.exit(
#                         f"{key} is not a known option in the template. These are the possible options: {list(possible_options.keys())}"
#                     )

#                 if possible_options[key] == "_any_":
#                     pass  # value can be any string

#                 else:
#                     if val not in possible_options[key]:
#                         sys.exit(
#                             f"{val} is not a possible value for {key}. These values are possible for {key}: {possible_options[key]}"
#                         )

#                 # overload to kwargs:

#                 if key == "data_structure":
#                     if val == "long":
#                         opt_kwargs["long_format"] = True
#                     elif val == "wide":
#                         opt_kwargs["long_format"] = False
#                     else:
#                         # single station
#                         opt_kwargs["long_format"] = True
#                 if key == "stationname":
#                     if not opt["data_structure"] == "single_station":
#                         logger.warning(
#                             f'{val} as {key} in the template options will be ignored because the datastructure is not "single_station" (but {opt["data_structure"]})'
#                         )
#                     else:
#                         opt_kwargs["single"] = val
#                 if key == "obstype":
#                     opt_kwargs["obstype"] = val
#                 if key == "obstype_unit":
#                     opt_kwargs["obstype_unit"] = val
#                 if key == "obstype_description":
#                     opt_kwargs["obstype_description"] = val
#                 if key == "timezone":
#                     opt_kwargs["timezone"] = val

#         else:
#             sys.exit(
#                 '"options" column found in the template, but no "options_values" found!'
#             )

#     # remove the options from the template
#     new_templ = templ.drop(columns=["options", "options_values"], errors="ignore")
#     return new_templ, opt_kwargs
